{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t04S9CDBjXyw",
        "outputId": "4b626a8c-9d3d-4092-8f6e-05ee18005c88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGDJFFDXkr8U"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from gensim.models import *\n",
        "import gensim.downloader\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZsPFxhoqe97"
      },
      "source": [
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUAiO7XEkvdE",
        "outputId": "d1cbd782-4862-4d4d-ba31-5adf52160f42"
      },
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/DLNLP/TrainData.csv\")\n",
        "df_train['Category'] = df_train['Category'].map({'business':0,'entertainment':1,'politics':2,'sport':3,'tech':4})\n",
        "df_train.columns = ['text','class']\n",
        "\n",
        "df_train['text'] = df_train.text.str.lower().str.replace(r'['+string.digits+string.punctuation+']', ' ')\n",
        "df_train['text'] = df_train['text'].apply(lambda x: x.split())\n",
        "\n",
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1490, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "ZfNHZtlElkmj",
        "outputId": "5be55234-47cb-4072-c5d7-c6f70b453b18"
      },
      "source": [
        "import scipy\n",
        "max = 0\n",
        "txt = ''\n",
        "row_len = []\n",
        "for i in range(df_train.shape[0]):\n",
        "  row_len.append(len(df_train.iloc[i]['text']))\n",
        "  if (len(df_train.iloc[i]['text']) >max):\n",
        "    max = len(df_train.iloc[i]['text'])\n",
        "    txt = df_train.iloc[i]['text']\n",
        "    \n",
        "              \n",
        "print(txt,max)\n",
        "print(scipy.stats.mode(row_len))\n",
        "print(np.mean(row_len))\n",
        "plt.plot(row_len)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['minimum', 'wage', 'increased', 'to', '£', 'the', 'minimum', 'wage', 'will', 'rise', 'in', 'october', 'benefiting', 'more', 'than', 'm', 'people', 'the', 'government', 'has', 'announced', 'adults', 'must', 'be', 'paid', 'at', 'least', '£', 'an', 'hour', 'up', 'from', '£', 'while', 'to', 'year', 'olds', 'will', 'be', 'paid', '£', 'the', 'recommendations', 'came', 'from', 'the', 'low', 'pay', 'commission', 'which', 'said', 'the', 'number', 'of', 'jobs', 'had', 'continued', 'to', 'grow', 'since', 'the', 'minimum', 'wage', 'was', 'introduced', 'in', 'businesses', 'wanted', 'it', 'frozen', 'warning', 'more', 'rises', 'could', 'damage', 'competitiveness', 'but', 'the', 'unions', 'want', 'a', '£', 'rate', 'a', 'further', 'increase', 'in', 'the', 'adult', 'rate', 'to', '£', 'an', 'hour', 'is', 'provisionally', 'scheduled', 'for', 'october', 'according', 'to', 'the', 'commission', 'many', 'businesses', 'had', 'found', 'the', 'last', 'two', 'significant', 'increases', 'in', 'the', 'minimum', 'wage', 'challenging', 'we', 'have', 'therefore', 'recommended', 'only', 'a', 'slight', 'increase', 'above', 'average', 'earnings', 'and', 'concentrated', 'it', 'in', 'the', 'second', 'year', 'to', 'allow', 'business', 'more', 'time', 'to', 'absorb', 'the', 'impact', 'said', 'chairman', 'adair', 'turner', 'the', 'government', 'says', 'most', 'of', 'those', 'on', 'the', 'minimum', 'wage', 'are', 'women', 'with', 'many', 'working', 'in', 'cleaning', 'catering', 'shops', 'and', 'hairdressing', 'unveiling', 'the', 'latest', 'increase', 'mr', 'blair', 'said', 'he', 'wanted', 'the', 'minimum', 'wage', 'to', 'become', 'a', 'symbol', 'of', 'decency', 'and', 'fairness', 'for', 'too', 'long', 'poverty', 'pay', 'capped', 'the', 'aspiration', 'and', 'prosperity', 'of', 'far', 'too', 'many', 'hard', 'working', 'families', 'he', 'said', 'too', 'often', 'people', 'were', 'told', 'to', 'make', 'a', 'choice', 'between', 'the', 'indignity', 'of', 'unemployment', 'or', 'the', 'humiliation', 'of', 'poverty', 'pay', 'chancellor', 'gordon', 'brown', 'and', 'transport', 'secretary', 'alistair', 'darling', 'promoted', 'the', 'news', 'in', 'edinburgh', 'wales', 'secretary', 'peter', 'hain', 'and', 'welsh', 'first', 'minister', 'rhodri', 'morgan', 'in', 'cardiff', 'and', 'northern', 'ireland', 'minister', 'john', 'spellar', 'in', 'belfast', 'the', 'government', 'has', 'not', 'accepted', 'the', 'commission', 's', 'recommendation', 'that', 'year', 'olds', 'should', 'be', 'paid', 'at', 'the', 'adult', 'rate', 'but', 'says', 'it', 'will', 'look', 'again', 'at', 'the', 'rate', 'later', 'on', 'mr', 'brown', 'said', 'we', 'want', 'to', 'do', 'nothing', 'that', 'can', 'damage', 'the', 'employment', 'opportunities', 'for', 'young', 'people', 'particularly', 'young', 'people', 'entering', 'the', 'labour', 'market', 'for', 'the', 'first', 'time', 'the', 'government', 'has', 'said', 'it', 'will', 'look', 'at', 'tougher', 'action', 'against', 'the', 'small', 'number', 'of', 'employers', 'who', 'consistently', 'refuse', 'to', 'pay', 'the', 'minimum', 'wage', 'the', 'national', 'minimum', 'wage', 'is', 'currently', 'set', 'at', '£', 'per', 'hour', 'for', 'those', 'aged', 'and', 'above', 'and', 'at', '£', 'for', 'those', 'aged', 'to', 'a', '£', 'per', 'hour', 'minimum', 'wage', 'was', 'introduced', 'last', 'october', 'for', 'to', 'year', 'olds', 'but', 'apprentices', 'are', 'exempt', 'the', 'trade', 'unions', 'congress', 'welcomed', 'the', 'increase', 'but', 'has', 'called', 'for', 'a', '£', 'minimum', 'wage', 'by', 'next', 'year', 'but', 'the', 'confederation', 'of', 'british', 'industry', 'cbi', 'called', 'for', 'a', 'pause', 'year', 'to', 'assess', 'the', 'impact', 'of', 'the', 'above', 'inflation', 'rise', 'in', 'the', 'minimum', 'wage', 'in', 'october', 'and', 'david', 'frost', 'director', 'of', 'the', 'british', 'chambers', 'of', 'commerce', 'said', 'the', 'level', 'of', 'increase', 'each', 'year', 'has', 'increased', 'by', 'rates', 'far', 'outstripping', 'the', 'rates', 'of', 'inflation', 'what', 'employers', 'are', 'saying', 'to', 'us', 'now', 'is', 'that', 'it', 's', 'at', 'a', 'level', 'where', 'it', 's', 'starting', 'to', 'bite', 'into', 'the', 'competitiveness', 'of', 'companies', 'right', 'across', 'the', 'country', 'the', 'liberal', 'democrats', 'economics', 'spokesman', 'vincent', 'cable', 'said', 'he', 'supported', 'the', 'move', 'to', 'raise', 'the', 'minimum', 'wage', 'it', 's', 'not', 'just', 'good', 'for', 'the', 'workers', 'themselves', 'but', 'it', 'lifts', 'them', 'out', 'of', 'benefits', 'and', 'therefore', 'is', 'good', 'for', 'the', 'exchequer', 'too', 'he', 'said', 'conservative', 'leader', 'michael', 'howard', 'said', 'he', 'accepted', 'the', 'principle', 'of', 'the', 'minimum', 'wage', 'and', 'would', 'not', 'seek', 'to', 'disturb', 'the', 'increase', 'speaking', 'on', 'bbc', 'radio', 's', 'woman', 's', 'hour', 'mr', 'howard', 'hinted', 'the', 'tories', 'might', 'go', 'into', 'the', 'general', 'election', 'with', 'a', 'promise', 'to', 'cancel', 'income', 'tax', 'for', 'the', 'lowest', 'paid', 'workers', 'there', 'are', 'people', 'on', 'very', 'low', 'salaries', 'very', 'low', 'incomes', 'indeed', 'who', 'really', 'shouldn', 't', 'be', 'paying', 'income', 'tax', 'he', 'said', 'it', 'would', 'be', 'better', 'to', 'decrease', 'taxes', 'on', 'earnings', 'below', '£', 'a', 'year', 'with', 'say', 'no', 'tax', 'on', 'below', '£', 'the', 'losses', 'in', 'tax', 'can', 'be', 'recouped', 'by', 'having', 'a', 'pc', 'tax', 'band', 'for', 'people', 'making', 'over', '£', 'our', 'minimum', 'wage', 'is', 'going', 'to', 'be', 'effectively', 'almost', 'twice', 'the', 'us', 'minimum', 'wage', 'yet', 'our', 'economy', 'per', 'person', 'is', 'only', 'rds', 'of', 'the', 'us', 'perhaps', 'we', 'have', 'to', 'really', 'starting', 'questioning', 'why', 'some', 'products', 'cost', 'more', 'here', 'than', 'they', 'do', 'in', 'the', 'us', 'this', 'combined', 'with', 'the', 'tax', 'decreases', 'would', 'make', 'the', 'pounds', 'the', 'low', 'paid', 'people', 'do', 'make', 'go', 'much', 'further', 'it', 's', 'still', 'not', 'good', 'enough', 'i', 'got', 'a', 'part', 'time', 'job', 'at', 'when', 'i', 'was', 'doing', 'my', 'a', 'levels', 'in', 'an', 'attempt', 'to', 'get', 'a', 'little', 'money', 'saved', 'for', 'uni', 'this', 'was', 'only', 'years', 'ago', 'and', 'i', 'was', 'getting', 'paid', '£', 'an', 'hour', 'and', 'working', 'as', 'hard', 'as', 'any', 'of', 'the', 'older', 'staff', 'maybe', 'it', 's', 'about', 'time', 'year', 'olds', 'got', 'a', 'fair', 'wage', 'we', 'must', 'remember', 'that', 'the', 'minimum', 'wage', 'is', 'only', 'part', 'of', 'the', 'picture', 'and', 'must', 'not', 'rise', 'to', 'a', 'level', 'that', 'makes', 'employing', 'people', 'unattractive', 'and', 'encourages', 'businesses', 'to', 'send', 'work', 'and', 'therefore', 'jobs', 'abroad', 'still', 'government', 'and', 'local', 'councils', 'employ', 'staff', 'via', 'their', 'contractors', 'that', 'pay', 'at', 'the', 'minimum', 'wage', 'or', 'very', 'close', 'to', 'it', 'an', 'easy', 'way', 'for', 'the', 'government', 'to', 'do', 'as', 'it', 'preaches', 'would', 'be', 'to', 'insist', 'on', 'floor', 'pay', 'levels', 'for', 'all', 'government', 'workers', 'and', 'take', 'tens', 'of', 'thousand', 'of', 'civil', 'servants', 'out', 'of', 'the', 'social', 'security', 'system', 'all', 'together', 'any', 'increase', 'is', 'certainly', 'welcome', 'news', 'however', 'for', 'all', 'those', 'whining', 'about', 'the', 'pressures', 'of', 'an', 'increase', 'in', 'the', 'minimum', 'wage', 'i', 'would', 'simply', 'ask', 'them', 'would', 'you', 'be', 'happy', 'to', 'work', 'for', 'less', 'than', '£', 'an', 'hour', 'thought', 'not', 'so', 'then', 'don', 't', 'expect', 'others', 'to', 'either', 'i', 'can', 't', 'believe', 'that', 'so', 'many', 'of', 'these', 'comments', 'are', 'against', 'the', 'minimum', 'wage', 'also', 'i', 'personally', 'take', 'great', 'offence', 'at', 'the', 'insinuation', 'that', 'people', 'earning', 'minimum', 'wage', 'were', 'lazy', 'at', 'school', 'if', 'everyone', 'went', 'to', 'university', 'then', 'who', 'would', 'serve', 'you', 'in', 'the', 'supermarkets', 'and', 'clean', 'up', 'after', 'you', 'it', 's', 'about', 'time', 'that', 'these', 'hardworking', 'people', 'are', 'rewarded', 'with', 'only', 'what', 'they', 'deserve', 'and', 'have', 'earned', 'fair', 'pay', 'and', 'a', 'bit', 'of', 'respect', 'wouldn', 't', 'go', 'a', 'miss', 'either', 'br', 'gt', 'this', 'is', 'good', 'news', 'the', 'minimum', 'wage', 'has', 'put', 'a', 'sense', 'of', 'equality', 'back', 'into', 'a', 'worker', 's', 'relationship', 'with', 'their', 'employer', 'wages', 'are', 'supposed', 'to', 'be', 'a', 'fair', 'reflection', 'of', 'an', 'employee', 's', 'efforts', 'for', 'too', 'long', 'wages', 'were', 'a', 'point', 'of', 'exploitation', 'what', 'could', 'an', 'employer', 'get', 'away', 'with', 'in', 'very', 'simplistic', 'terms', 'this', 'put', 'a', 'pressure', 'to', 'keep', 'low', 'paid', 'wages', 'low', 'with', 'the', 'minimum', 'wage', 'this', 'downward', 'pressure', 'is', 'at', 'least', 'partly', 'removed', 'it', 'is', 'also', 'interesting', 'to', 'read', 'the', 'comments', 'from', 'so', 'called', 'business', 'leaders', 'they', 'are', 'the', 'first', 'to', 'defend', 'the', 'rights', 'and', 'privileges', 'of', 'boards', 'to', 'award', 'fat', 'cat', 'salaries', 'bonuses', 'and', 'pension', 'rights', 'to', 'the', 'select', 'few', 'but', 'they', 'are', 'the', 'first', 'to', 'attack', 'policies', 'that', 'are', 'put', 'in', 'place', 'to', 'merely', 'defend', 'the', 'rights', 'of', 'those', 'that', 'really', 'make', 'those', 'fat', 'cats', 'purr', 'i', 'feel', 'there', 'are', 'both', 'negatives', 'and', 'positives', 'to', 'the', 'increase', 'on', 'one', 'hand', 'some', 'businesses', 'will', 'struggle', 'to', 'stay', 'afloat', 'but', 'on', 'the', 'other', 'hand', 'in', 'today', 'world', 'many', 'young', 'people', 'can', 't', 'afford', 'to', 'move', 'out', 'as', 'property', 'costs', 'too', 'much', 'and', 'only', 'by', 'earning', 'more', 'will', 'they', 'be', 'able', 'to', 'get', 'on', 'in', 'life', 'its', 'true', 'many', 'may', 'get', 'complacent', 'but', 'the', 'minimum', 'wage', 'could', 'be', 'looked', 'at', 'as', 'more', 'of', 'a', 'stepping', 'stone', 'rather', 'than', 'a', 'hand', 'out', 'here', 'come', 'the', 'usual', 'whines', 'about', 'how', 'difficult', 'it', 'will', 'be', 'for', 'businesses', 'we', 'all', 'remember', 'michael', 'howard', 's', 'protestations', 'that', 'the', 'minimum', 'wage', 'would', 'cost', 'a', 'million', 'jobs', 'when', 'it', 'was', 'introduced', 'funny', 'how', 'he', 's', 'gone', 'quiet', 'on', 'that', 'one', 'jobs', 'have', 'continued', 'to', 'increase', 'since', 'this', 'humane', 'legislation', 'was', 'brought', 'in', 'i', 'think', 'if', 'any', 'job', 'is', 'worth', 'doing', 'then', 'it', 's', 'worth', 'being', 'paid', 'a', 'fair', 'wage', 'for', 'and', '£', 'is', 'hardly', 'a', 'fortune', 'if', 'your', 'business', 'cannot', 'pay', 'its', 'workers', 'a', 'decent', 'wage', 'then', 'maybe', 'it', 's', 'not', 'being', 'run', 'properly', 'and', 'if', 'it', 'folds', 'a', 'better', 'run', 'company', 'will', 'take', 'over', 'its', 'duties', 'and', 'employ', 'more', 'people', 'so', 'everybody', 'wins', 'except', 'incompetent', 'business', 'owners', 'great', 'keep', 'at', 'it', 'tony', 'i', 'remember', 'the', 'despair', 'of', 'the', 's', 'and', 'the', 'low', 'wages', 'employers', 'got', 'away', 'with', 'at', 'last', 'we', 'can', 'make', 'a', 'difference', 'to', 'people', 'and', 'reward', 'them', 'for', 'working', 'we', 'can', 't', 'afford', 'not', 'to', 'pay', 'a', 'decent', 'wage', 'it', 's', 'not', 'a', 'jobs', 'at', 'any', 'price', 'economy', 'goodbye', 'sweatshops', 'hello', 'decency', 'the', 'increase', 'in', 'minimum', 'wage', 'is', 'a', 'good', 'thing', 'living', 'in', 'the', 'southwest', 'where', 'house', 'prices', 'and', 'rent', 'have', 'increased', 'hugely', 'like', 'the', 'rest', 'of', 'the', 'country', 'over', 'the', 'past', 'years', 'has', 'made', 'living', 'for', 'you', 'average', 'years', 'old', 'very', 'difficult', 'in', 'the', 'south', 'west', 'the', 'increase', 'in', 'living', 'costs', 'have', 'not', 'been', 'matched', 'by', 'an', 'increase', 'in', 'pay', 'for', 'example', 'a', 'job', 'i', 'did', 'in', 'plymouth', 'was', 'underpaid', 'to', 'an', 'equivalent', 'worker', 'in', 'exeter', 'by', 'p', 'an', 'hour', 'hopefully', 'the', 'increase', 'in', 'the', 'minimum', 'wage', 'will', 'bring', 'in', 'to', 'balance', 'pay', 'on', 'a', 'regional', 'and', 'national', 'level', 'and', 'in', 'turn', 'allow', 'people', 'like', 'myself', 'who', 'do', 'work', 'hard', 'but', 'might', 'never', 'earn', 'a', 'figure', 'salary', 'the', 'chance', 'to', 'branch', 'out', 'on', 'our', 'own', 'i', 'work', 'at', 'a', 'large', 'hospital', 'where', 'the', 'contractors', 'providing', 'all', 'ancillary', 'services', 'domestic', 'catering', 'portering', 'etc', 'pay', 'the', 'minimum', 'wage', 'of', '£', 'as', 'the', 'basic', 'rate', 'someone', 'has', 'to', 'do', 'these', 'unglamorous', 'jobs', 'and', 'earn', 'enough', 'to', 'live', 'decently', 'how', 'dare', 'people', 'suggest', 'we', 'are', 'lazy', 'or', 'complacent', 'for', 'accepting', 'these', 'jobs', 'and', 'these', 'wages', 'who', 'do', 'they', 'think', 'will', 'be', 'carrying', 'out', 'these', 'public', 'service', 'jobs', 'if', 'contractors', 'are', 'allowed', 'to', 'pay', 'as', 'little', 'as', 'their', 'consciences', 'allow', 'this', 'is', 'definitely', 'the', 'right', 'step', 'in', 'the', 'right', 'direction', 'it', 'shows', 'that', 'this', 'government', 'cares', 'for', 'the', 'low', 'income', 'earners', 'as', 'well', 'this', 'is', 'a', 'million', 'votes', 'more', 'good', 'strategy', 'isn', 't', 'it', 'although', 'i', 'would', 'not', 'deny', 'people', 'the', 'minimum', 'wage', 'increase', 'its', 'timing', 'stinks', 'i', 'am', 'quite', 'prepared', 'for', 'a', 'raft', 'of', 'bribes', 'to', 'come', 'from', 'the', 'government', 'before', 'the', 'election', 'and', 'a', 'raft', 'of', 'taxes', 'afterwards', 'they', 'are', 'playing', 'us', 'for', 'the', 'fools', 'they', 'think', 'we', 'are', 'this', 'is', 'extremely', 'bad', 'news', 'for', 'any', 'business', 'whether', 'they', 'are', 'small', 'and', 'medium', 'enterprises', 'or', 'even', 'large', 'companies', 'by', 'increasing', 'overheads', 'for', 'business', 'there', 'will', 'be', 'an', 'almost', 'certain', 'rise', 'in', 'costs', 'to', 'the', 'consumer', 'who', 'while', 'they', 'openly', 'welcome', 'the', 'idea', 'of', 'an', 'increase', 'in', 'the', 'minimum', 'wage', 'are', 'the', 'same', 'people', 'who', 'still', 'want', 'to', 'buy', 'that', 'shirt', 'or', 'that', 'pair', 'of', 'trainers', 'for', 'next', 'to', 'nothing', 'the', 'extra', 'cost', 'this', 'increase', 'will', 'bring', 'will', 'only', 'be', 'reflected', 'in', 'the', 'price', 'of', 'the', 'goods', 'we', 'buy', 'which', 'in', 'turn', 'will', 'only', 'serve', 'to', 'discourage', 'companies', 'from', 'setting', 'up', 'business', 'in', 'the', 'uk', 'or', 'encourage', 'those', 'companies', 'already', 'based', 'here', 'to', 'look', 'elsewhere', 'the', 'jubilation', 'felt', 'by', 'low', 'paid', 'workers', 'here', 'will', 'soon', 'give', 'way', 'to', 'misery', 'as', 'they', 'lose', 'their', 'jobs', 'this', 'will', 'only', 'lead', 'to', 'a', 'reduction', 'in', 'jobs', 'why', 'have', 'many', 'of', 'the', 'call', 'centre', 'jobs', 'gone', 'to', 'india', 'blair', 'say', 's', 'the', 'economy', 'is', 'strong', 'and', 'stable', 'economy', 'however', 'consumer', 'debt', 'and', 'the', 'country', 's', 'debt', 'is', 'at', 'its', 'highest', 'and', 'now', 'they', 'heap', 'this', 'onto', 'businesses', 'that', 'will', 'have', 'no', 'choice', 'but', 'to', 'cut', 'the', 'workforce', 'the', 'timing', 'cannot', 'be', 'coincidental', 'this', 'is', 'blatant', 'electioneering', 'and', 'should', 'be', 'exposed', 'as', 'such', 'andrew', 'in', 'derby', 'complains', 'that', 'raising', 'the', 'minimum', 'wage', 'is', 'blatant', 'electioneering', 'i', 'don', 't', 'mind', 'if', 'it', 'is', 'in', 'our', 'degraded', 'democracy', 'elections', 'are', 'the', 'one', 'time', 'when', 'elites', 'really', 'have', 'to', 'worry', 'about', 'doing', 'something', 'concrete', 'for', 'the', 'majority', 'my', 'only', 'complaint', 'is', 'the', 'paltry', 'figures', 'being', 'discussed', 'if', 'my', 'maths', 'is', 'right', 'a', 'hour', 'week', 'at', '£', 'gives', 'you', 'an', 'annual', 'income', 'just', 'over', '£', 'and', 'raising', 'it', 'to', '£', 'leaves', 'it', 'under', '£', 'the', 'unions', 'should', 'be', 'putting', 'the', 'government', 'under', 'pressure', 'for', 'much', 'more', 'businesses', 'complaining', 'might', 'like', 'to', 'take', 'a', 'look', 'at', 'corporate', 'pay', 'shareholder', 'payouts', 'and', 'profits', 'before', 'wondering', 'if', 'paying', 'a', 'living', 'wage', 'is', 'really', 'a', 'controlling', 'factor', 'in', 'the', 'viability', 'of', 'their', 'firm', 'i', 'am', 'all', 'for', 'lifting', 'the', 'minimum', 'wage', 'of', 'workers', 'to', 'a', 'reasonable', 'level', 'but', 'we', 'have', 'to', 'accept', 'that', 'with', 'this', 'will', 'come', 'competition', 'from', 'overseas', 'workers', 'also', 'small', 'businesses', 'will', 'have', 'to', 'be', 'able', 'to', 'afford', 'this', 'manpower', 'cost', 'we', 'are', 'already', 'seeing', 'a', 'sweeping', 'change', 'in', 'it', 'work', 'being', 'lost', 'to', 'india', 'where', 'people', 'are', 'paid', 'much', 'less', 'it', 'is', 'difficult', 'for', 'me', 'to', 'understand', 'that', 'only', 'five', 'years', 'ago', 'cheap', 'labour', 'abroad', 'was', 'classified', 'as', 'sweat', 'shop', 'but', 'now', 'we', 'are', 'told', 'it', 'is', 'global', 'competition', 'with', 'our', 'manufacturing', 'industry', 'in', 'serious', 'decline', 'the', 'country', 'cannot', 'be', 'entirely', 'service', 'industries', 'without', 'something', 'tangible', 'to', 'serve', 'there', 'has', 'to', 'be', 'something', 'at', 'the', 'top', 'of', 'the', 'food', 'chain', 'and', 'that', 'is', 'manufacturing', 'the', 'whole', 'picture', 'needs', 'to', 'be', 'looked', 'at', 'this', 'is', 'great', 'news', 'but', 'that', 'might', 'be', 'because', 'i', 'work', 'for', 'minimum', 'wage', 'seems', 'a', 'good', 'idea', 'and', 'will', 'hopefully', 'be', 'an', 'incentive', 'to', 'those', 'who', 'live', 'to', 'claim', 'to', 'actually', 'get', 'a', 'job', 'when', 'you', 'can', 'earn', 'more', 'from', 'claiming', 'than', 'you', 'can', 'from', 'work', 'there', 'is', 'no', 'incentive', 'perhaps', 'a', 'step', 'in', 'the', 'right', 'direction', 'if', 'the', 'tuc', 'get', 'their', 'way', 'a', 'very', 'large', 'number', 'of', 'smes', 'will', 'have', 'to', 'close', 'this', 'will', 'put', 'more', 'people', 'out', 'of', 'work', 'how', 'then', 'will', 'the', 'government', 'fudge', 'the', 'unemployment', 'figures', 'the', 'government', 'know', 'it', 'is', 'not', 'big', 'business', 'that', 'keeps', 'the', 'economy', 'going', 'but', 'the', 'smes', 'but', 'we', 'always', 'get', 'overlooked', 'they', 'will', 'only', 'take', 'notice', 'if', 'these', 'large', 'corporations', 'close', 'and', 'move', 'to', 'other', 'countries', 'after', 'all', 'they', 'are', 'predominantly', 'owned', 'by', 'foreign', 'companies', 'we', 'are', 'a', 'specialist', 'company', 'but', 'with', 'these', 'increases', 'have', 'already', 'had', 'an', 'effect', 'on', 'us', 'and', 'we', 'have', 'lost', 'work', 'another', 'one', 'will', 'close', 'us', 'while', 'i', 'm', 'delighted', 'for', 'those', 'on', 'low', 'pay', 'that', 'this', 'increase', 'is', 'being', 'put', 'forward', 'i', 'am', 'extremely', 'concerned', 'at', 'the', 'implications', 'for', 'small', 'businesses', 'as', 'an', 'employee', 'for', 'a', 'small', 'nursery', 'i', 'know', 'this', 'increase', 'will', 'cause', 'great', 'hardship', 'for', 'my', 'employer', 'who', 'has', 'been', 'unable', 'to', 'increase', 'salaries', 'for', 'higher', 'paid', 'employees', 'because', 'of', 'last', 'october', 's', 'increase', 'for', 'the', 'lower', 'paid', 'employees', 'who', 'were', 'originally', 'being', 'paid', 'slightly', 'above', 'the', 'minimum', 'but', 'are', 'now', 'on', 'the', 'minimum', 'this', 'latest', 'increase', 'of', 'p', 'an', 'hour', 'will', 'cause', 'even', 'more', 'financial', 'hardship', 'if', 'the', 'rate', 'rises', 'to', '£', 'then', 'i', 'can', 'foresee', 'many', 'small', 'businesses', 'having', 'to', 'pay', 'off', 'employees', 'the', 'increase', 'in', 'minimum', 'wage', 'will', 'have', 'a', 'serious', 'effect', 'on', 'my', 'business', 'although', 'we', 'pay', 'above', 'the', 'minimum', 'level', 'we', 'will', 'have', 'to', 'increase', 'our', 'pay', 'rates', 'to', 'maintain', 'the', 'differential', 'the', 'raise', 'is', 'well', 'above', 'inflation', 'and', 'without', 'significant', 'increases', 'in', 'sales', 'it', 'will', 'mean', 'that', 'i', 'will', 'not', 'be', 'taking', 'on', 'a', 'new', 'member', 'of', 'staff', 'as', 'planned', 'and', 'i', 'will', 'be', 'looking', 'to', 'reduce', 'the', 'total', 'hours', 'worked', 'by', 'the', 'other', 'members', 'of', 'staff', 'overtime', 'being', 'the', 'first', 'to', 'go', 'i', 'currently', 'employ', 'staff', 'whose', 'wages', 'mirror', 'the', 'national', 'minimum', 'wage', 'increases', 'above', 'inflation', 'are', 'fine', 'but', 'all', 'of', 'my', 'business', 'is', 'conducted', 'with', 'local', 'authorities', 'who', 'will', 'not', 'accept', 'above', 'inflation', 'rises', 'in', 'my', 'service', 'delivery', 'of', 'my', 'costs', 'are', 'labour', 'the', 'other', 'aspect', 'that', 'is', 'always', 'hidden', 'is', 'that', 'the', 'thresholds', 'for', 'tax', 'credits', 'do', 'not', 'move', 'in', 'line', 'with', 'these', 'increases', 'so', 'that', 'all', 'that', 'happens', 'is', 'that', 'employees', 'tax', 'credit', 'support', 'is', 'reduced', 'by', 'the', 'amount', 'of', 'the', 'increase', 'thereby', 'saving', 'the', 'government', 'money', 'but', 'increasing', 'the', 'financial', 'burden', 'on', 'small', 'to', 'medium', 'businesses', 'it', 'is', 'very', 'good', 'that', 'the', 'government', 'has', 'decided', 'to', 'increase', 'the', 'minimum', 'wage', 'this', 'should', 'hopefully', 'motivate', 'people', 'to', 'undertake', 'the', 'lower', 'status', 'jobs', 'i', 'know', 'about', 'this', 'great', 'idea', 'don', 't', 'bother', 'getting', 'qualifications', 'laze', 'about', 'at', 'school', 'no', 'need', 'to', 'do', 'anything', 'other', 'than', 'attend', 'so', 'your', 'parents', 'don', 't', 'get', 'fined', 'because', 'remember', 'when', 'you', 'do', 'eventually', 'start', 'working', 'doesn', 't', 'matter', 'how', 'lazy', 'you', 'are', 'you', 'll', 'be', 'guaranteed', 'a', 'decent', 'wage', 'the', 'ones', 'who', 'suffer', 'are', 'the', 'employers', 'i', 'hope', 'that', 'if', 'industry', 'and', 'business', 'have', 'to', 'pay', 'this', 'new', 'rate', 'that', 'mr', 'blair', 'and', 'mr', 'brown', 'will', 'increase', 'tax', 'allowances', 'and', 'raise', 'national', 'insurance', 'thresholds', 'so', 'that', 'the', 'treasury', 'won', 't', 'take', 'some', 'of', 'this', 'increase', 'off', 'the', 'people', 'they', 'say', 'they', 'are', 'helping', 'or', 'is', 'this', 'just', 'another', 'form', 'of', 'stealth', 'tax', 'on', 'business', 'through', 'the', 'back', 'door', 'i', 'don', 't', 'believe', 'in', 'the', 'minimum', 'wage', 'at', 'all', 'i', 'think', 'jobs', 'should', 'create', 'their', 'own', 'wage', 'value', 'and', 'that', 'if', 'people', 'want', 'higher', 'wages', 'they', 'should', 'earn', 'them', 'now', 'before', 'everyone', 'thinks', 'that', 'i', 'am', 'some', 'rich', 'kid', 'i', 'can', 'assure', 'you', 'i', 'am', 'not', 'i', 'came', 'from', 'a', 'very', 'much', 'working', 'class', 'background', 'and', 'started', 'work', 'years', 'ago', 'on', 'a', 'youth', 'opportunity', 'program', 'earning', '£', 'per', 'week', 'i', 'worked', 'hard', 'went', 'to', 'college', 'part', 'time', 'got', 'my', 'a', 'levels', 'and', 'degree', 'bettered', 'myself', 'i', 'now', 'earn', 'a', 'figure', 'salary', 'i', 'did', 'that', 'through', 'hard', 'work', 'and', 'getting', 'off', 'my', 'backside', 'a', 'minimum', 'wage', 'just', 'makes', 'people', 'complacent', 'to', 'ashley', 'of', 'swindon', 'when', 'you', 'earned', '£', 'per', 'week', 'it', 'was', 'worth', 'something', 'these', 'days', 'that', '£', 'would', 'need', 'to', 'be', 'near', 'to', '£', 'to', 'have', 'the', 'equivalent', 'buying', 'power', 'i', 'might', 'add', 'that', 'thanks', 'to', 'successive', 'governments', 'holding', 'down', 'the', 'tax', 'allowance', 'threshold', 'below', 'inflation', 'people', 'earning', 'the', 'minimum', 'wage', 'are', 'paying', 'taxes', 'that', 'they', 'never', 'would', 'have', 'done', 'years', 'ago', 'at', 'equivalent', 'wages', 'in', 'my', 'day', 'type', 'arguments', 'are', 'a', 'view', 'that', 'belong', 'in', 'the', 'your', 'day', 'years', 'ago', 'as', 'a', 'graduate', 'working', 'for', 'minimum', 'wage', 'i', 'welcome', 'any', 'increase', 'of', 'pay', 'i', 'can', 'get', 'i', 'disagree', 'with', 'ashley', 'swindon', 'saying', 'i', 'have', 'to', 'work', 'harder', 'to', 'get', 'more', 'pay', 'i', 'have', 'my', 'gcse', 's', 'a', 'levels', 'and', 'a', 'degree', 'and', 'have', 'chosen', 'to', 'work', 'for', 'a', 'small', 'business', 'that', 'can', 't', 'afford', 'the', 'wages', 'i', 'should', 'be', 'getting', 'i', 'should', 'be', 'on', 'at', 'least', 'x', 'what', 'i', 'm', 'getting', 'but', 'they', 'can', 't', 'afford', 'it', 'we', 'all', 'work', 'hard', 'but', 'the', 'money', 'is', 'just', 'not', 'there', 'but', 'on', 'the', 'plus', 'side', 'i', 'love', 'my', 'job', 'and', 'wouldn', 't', 'change', 'it', 'just', 'to', 'get', 'more', 'pay', 'as', 'an', 'employer', 'of', 'staff', 'in', 'several', 'shops', 'the', 'last', 'rise', 'in', 'the', 'minimum', 'wage', 'cost', 'my', 'company', 'an', 'additional', '£', 'per', 'year', 'these', 'next', 'rises', 'will', 'cost', 'me', 'more', 'i', 'have', 'to', 'get', 'the', 'money', 'from', 'somewhere', 'so', 'pass', 'it', 'on', 'to', 'customers', 'so', 'no', 'one', 'really', 'wins', 'in', 'the', 'end', 'in', 'answer', 'to', 'emma', 'from', 'sleaford', 'regarding', 'no', 'one', 'really', 'wins', 'in', 'the', 'end', 'on', 'the', 'contrary', 'mr', 'blair', 'wins', 'he', 'wins', 'because', 'he', 'obviously', 'has', 'announced', 'this', 'to', 'be', 'a', 'vote', 'winner', 'and', 'his', 'treasury', 'wins', 'because', 'as', 'an', 'employer', 'you', 'will', 'know', 'that', 'the', 'amount', 'of', 'tax', 'and', 'national', 'insurance', 'that', 'the', 'government', 'will', 'receive', 'from', 'all', 'the', 'minimum', 'wage', 'increases', 'will', 'rise', 'and', 'of', 'course', 'not', 'only', 'will', 'be', 'paying', 'out', 'higher', 'wages', 'but', 'as', 'an', 'employer', 'higher', 'employer', 'ni', 'contributions', 'as', 'well', 'if', 'the', 'minimum', 'wage', 'increases', 'again', 'and', 'if', 'it', 'hits', 'anywhere', 'near', 'the', '£', 'mark', 'there', 'will', 'be', 'more', 'people', 'on', 'the', 'employment', 'line', 'and', 'one', 'more', 'small', 'business', 'going', 'bankrupt', 'namely', 'mine', 'think', 'of', 'us', 'employers', 'as', 'well', 'mr', 'blair', 'we', 'are', 'not', 'all', 'big', 'corporations', 'earning', 'millions', 'all', 'workers', 'should', 'be', 'entitled', 'to', 'a', 'fair', 'day', 's', 'pay', 'for', 'a', 'fair', 'day', 's', 'work', 'how', 'many', 'people', 'on', 'the', 'minimum', 'wage', 'have', 'any', 'hope', 'of', 'obtaining', 'a', 'mortgage', 'or', 'saving', 'towards', 'retirement', 'it', 'is', 'good', 'news', 'for', 'many', 'asians', 'living', 'in', 'uk', 'students', 'who', 'do', 'odd', 'jobs', 'can', 'increase', 'their', 'income', 'and', 'can', 'help', 'there', 'family', 'in', 'their', 'home', 'country', 'i', 'thank', 'mr', 'blair', 'and', 'his', 'government', 'for', 'increase', 'in', 'the', 'national', 'minimum', 'wage'] 3308\n",
            "ModeResult(mode=array([274]), count=array([10]))\n",
            "381.5543624161074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc259887c50>]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "WvwHdRLXVNMo",
        "outputId": "60e9670e-f203-48a1-ad5b-da0c79ebde14"
      },
      "source": [
        "fig, ax = plt.subplots(figsize =(10, 7))\n",
        "ax.hist(row_len, bins = [0, 250,350,450, 500])\n",
        " \n",
        "# Show plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dgNXz4RnPu1",
        "outputId": "ee4cf030-788b-416e-a286-86a51f35addf"
      },
      "source": [
        "gv = gensim.downloader.load('glove-wiki-gigaword-300')\n",
        "w2v = gensim.downloader.load('word2vec-google-news-300') \n",
        "ft = gensim.downloader.load('fasttext-wiki-news-subwords-300') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW3rvIOhna7h",
        "outputId": "99d81feb-31e5-4d26-a0c9-f34601ae1704"
      },
      "source": [
        "es = 300\n",
        "\n",
        "str_len = 500\n",
        "tz = Tokenizer(lower=True)\n",
        "tz.fit_on_texts(df_train['text'])\n",
        "X_train = tz.texts_to_sequences(df_train['text'])\n",
        "X_train = pad_sequences(X_train, maxlen=str_len)\n",
        "X_train = np.asarray(X_train)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0208bf5e597e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstr_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khm1U-_8Bywd",
        "outputId": "698180a9-7960-484c-b9ee-8245559d62c2"
      },
      "source": [
        "df_test = pd.read_csv(\"/content/drive/MyDrive/DLNLP/TestData.csv\",encoding='ISO 8859-1')\n",
        "df_test['Class'] = df_test['Class'].map({'business':0,'entertainment':1,'politics':2,'sport':3,'tech':4})\n",
        "df_test = df_test[['Text','Class']]\n",
        "df_test.columns = ['text','class']\n",
        "\n",
        "\n",
        "df_test['text'] = df_test.text.str.lower().str.replace(r'['+string.digits+string.punctuation+']', ' ')\n",
        "df_test['text'] = df_test['text'].apply(lambda x: x.split())\n",
        "\n",
        "print(df_test.shape)\n",
        "\n",
        "X_test = tz.texts_to_sequences(df_test['text'])\n",
        "X_test = pad_sequences(X_test, maxlen=str_len)\n",
        "X_test = np.asarray(X_test)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(735, 2)\n",
            "(735, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVYF5Eucue3k",
        "outputId": "ff5ce8ca-07a1-403a-f843-f6b8fb18edc4"
      },
      "source": [
        "       \n",
        "gv_embedding = np.random.random((len(tz.word_index) + 1, es))\n",
        "w2v_embedding = np.random.random((len(tz.word_index) + 1, es))\n",
        "ft_embedding = np.random.random((len(tz.word_index) + 1, es))\n",
        "\n",
        "for word,i in tz.word_index.items():\n",
        "    try:\n",
        "      gv_embedding[i] = gv.wv[word]\n",
        "    except:\n",
        "      gv_embedding[i] = np.zeros((es,))\n",
        "    try:\n",
        "      w2v_embedding[i] = w2v.wv[word]\n",
        "    except:\n",
        "      w2v_embedding[i] = np.zeros((es,))\n",
        "    try:\n",
        "      ft_embedding[i] = ft.wv[word]\n",
        "    except:\n",
        "      ft_embedding[i] = np.zeros((es,))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WmdVZDnuhmL"
      },
      "source": [
        "def ProjEmbLayer(embeddings, str_len):\n",
        "    \n",
        "    inputs = []\n",
        "    output = []\n",
        "    inp = Input(shape=(str_len,))\n",
        "    for embedding in embeddings:  \n",
        "        emb = Embedding(len(tz.word_index) + 1, es, weights=[embedding], trainable=False)(inp)\n",
        "        emb = Reshape((-1,es,1))(emb)\n",
        "        proj = projection(str_len)\n",
        "        x = proj(Reshape((-1,es))(emb))\n",
        "        output.append(Reshape((-1,es,1))(x))    \n",
        "    return Model(inp, Concatenate(axis=-1)(output))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vywLGsI9ukd0"
      },
      "source": [
        "def EmbLayer(embeddings, str_len):\n",
        "    \n",
        "    inputs = []\n",
        "    output = []\n",
        "    inp = Input(shape=(str_len,))\n",
        "    for embedding in embeddings:  \n",
        "        \n",
        "        emb = Embedding(len(tz.word_index) + 1, es, weights=[embedding], trainable=False)(inp)\n",
        "        emb = Reshape((-1,es,1))(emb)\n",
        "        \n",
        "        output.append(emb)    \n",
        "    return Model(inp, Concatenate(axis=-1)(output))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFOORkvFulCW"
      },
      "source": [
        "\n",
        "def projection(str_len):\n",
        "\n",
        "    inp = Input(shape=(str_len, es))\n",
        "    out = Dense(es,activation=None)(inp)\n",
        "\n",
        "    return Model(inp, out)\n",
        "\n",
        "def myDynamicMetaEmbedding(str_len):\n",
        "    inp = Input(shape=(str_len, es, n))\n",
        "    proj2mul  = Reshape((str_len, es,n))(inp)    ## (None, 30, 300, 3)\n",
        "    proj = Permute((1,3, 2)) (proj2mul)          ## (None, 30, 3, 300)\n",
        "    alphas = Dense(1,activation=None)(proj)      ## (None, 30, 3, 1)\n",
        "    alphas = Activation('softmax')(alphas)       ## (None, 30, 3, 1)\n",
        "    alphas2mul = Permute((1,3, 2)) (alphas)      ## (None, 30, 1, 3)\n",
        "    x = multiply([proj2mul, alphas2mul])         ## (None, 30, 300, 3)\n",
        "    out = Lambda(lambda t: K.sum(t, axis=-1))(x) ## (None, 30, 300)\n",
        "    print('Out',out.shape)                      \n",
        "\n",
        "    return Model(inp, out)\n",
        "\n",
        "### WRONG ###\n",
        "\n",
        "    # proj = Reshape((maxlen, es,n))(temp)\n",
        "    # alphas = Dense(n,activation=None)(temp)\n",
        "    # alphas = Activation('softmax')(alphas)\n",
        "    # alphas = Reshape((maxlen,1,n))(alphas)\n",
        "    # x = multiply([proj,alphas])\n",
        "    # out = Lambda(lambda t: K.sum(t, axis=-1))(x)\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDEb7eaGum9s"
      },
      "source": [
        "n=3\n",
        "embLayer = ProjEmbLayer([w2v_embedding,gv_embedding, ft_embedding], str_len)\n",
        "dme = myDynamicMetaEmbedding(str_len)\n",
        "x = dme(embLayer.output)\n",
        "x = LSTM(64)(x)\n",
        "out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "model1 = Model(embLayer.input, out)\n",
        "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model1.fit(X_train, df_train['class'], batch_size=64, epochs=10, verbose=1, validation_split=0.1,callbacks=[callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuGnni0SP65T"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(\"TEST SET\",f1_score(df_test['class'],np.argmax(model1.predict(X_test), axis=-1),average='micro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrx31NndGNUG"
      },
      "source": [
        "n=3\n",
        "embLayer = ProjEmbLayer([w2v_embedding,gv_embedding, ft_embedding], str_len)\n",
        "dme = myDynamicMetaEmbedding(str_len)\n",
        "x = dme(embLayer.output)\n",
        "print(x.shape)\n",
        "x = Bidirectional(LSTM(64,return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "x = MultiHeadAttention(num_heads=1, key_dim=128) (x,x,x)\n",
        "print(x.shape)\n",
        "x = Flatten()(x)\n",
        "print(x.shape)\n",
        "out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = Model(embLayer.input, out)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(X_train, df_train['class'], batch_size=64, epochs=10, verbose=1, validation_split=0.1,callbacks=[callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah_hBIgqV3lM"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(\"TEST SET\",f1_score(df_test['class'],np.argmax(model.predict(X_test), axis=-1),average='micro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwLoS1oGyiFM"
      },
      "source": [
        "n=3\n",
        "embLayer = ProjEmbLayer([w2v_embedding,gv_embedding, ft_embedding], str_len)\n",
        "dme = myDynamicMetaEmbedding(str_len)\n",
        "x = dme(embLayer.output)\n",
        "\n",
        "x = Conv1D(32, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling1D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(250, activation='relu')(x)\n",
        "\n",
        "out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "model2 = Model(embLayer.input, out)\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model2.fit(X_train, df_train['class'], batch_size=64, epochs=10, verbose=1, validation_split=0.1,callbacks=[callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU_oTQGjZGpR"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(\"TEST SET\",f1_score(df_test['class'],np.argmax(model2.predict(X_test), axis=-1),average='micro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu9KAZ9f10VQ",
        "outputId": "941bd4ff-2f70-4d77-f58d-34b2482a7b95"
      },
      "source": [
        "n=3\n",
        "embLayer = ProjEmbLayer([w2v_embedding,gv_embedding, ft_embedding], str_len)\n",
        "dme = myDynamicMetaEmbedding(str_len)\n",
        "x = dme(embLayer.output)\n",
        "\n",
        "x = Conv1D(64, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling1D()(x)\n",
        "\n",
        "\n",
        "print(x.shape)\n",
        "x = LSTM(64,return_sequences=True)(x)\n",
        "print(x.shape)\n",
        "attention = Dense(1, activation=\"tanh\")(x)\n",
        "print(attention.shape)\n",
        "attention = Flatten()(attention)\n",
        "print(attention.shape)\n",
        "attention = Activation(\"softmax\")(attention)\n",
        "print(attention.shape)\n",
        "attention = RepeatVector(64 )(attention)\n",
        "print(attention.shape)\n",
        "attention = Permute([2,1])(attention)\n",
        "print(attention.shape)\n",
        "x = Multiply()([x, attention])\n",
        "print(x.shape)\n",
        "x = Lambda(lambda xin: K.sum(xin, axis=-2),\n",
        "                            output_shape=(64,))(x)\n",
        "\n",
        "\n",
        "print(x.shape)\n",
        "out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "model3 = Model(embLayer.input, out)\n",
        "model3.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model3.summary()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model3.fit(X_train, df_train['class'], batch_size=64, epochs=100, verbose=1, validation_split=0.1,callbacks=[callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out (None, 500, 300)\n",
            "(None, 250, 64)\n",
            "(None, 250, 64)\n",
            "(None, 250, 1)\n",
            "(None, 250)\n",
            "(None, 250)\n",
            "(None, 64, 250)\n",
            "(None, 250, 64)\n",
            "(None, 250, 64)\n",
            "(None, 64)\n",
            "Model: \"model_113\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_91 (InputLayer)           [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_54 (Embedding)        (None, 500, 300)     7067100     input_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_55 (Embedding)        (None, 500, 300)     7067100     input_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_56 (Embedding)        (None, 500, 300)     7067100     input_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_180 (Reshape)           (None, 500, 300, 1)  0           embedding_54[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_183 (Reshape)           (None, 500, 300, 1)  0           embedding_55[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_186 (Reshape)           (None, 500, 300, 1)  0           embedding_56[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_181 (Reshape)           (None, 500, 300)     0           reshape_180[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_184 (Reshape)           (None, 500, 300)     0           reshape_183[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_187 (Reshape)           (None, 500, 300)     0           reshape_186[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "model_108 (Functional)          (None, 500, 300)     90300       reshape_181[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "model_109 (Functional)          (None, 500, 300)     90300       reshape_184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "model_110 (Functional)          (None, 500, 300)     90300       reshape_187[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_182 (Reshape)           (None, 500, 300, 1)  0           model_108[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_185 (Reshape)           (None, 500, 300, 1)  0           model_109[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_188 (Reshape)           (None, 500, 300, 1)  0           model_110[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 500, 300, 3)  0           reshape_182[0][0]                \n",
            "                                                                 reshape_185[0][0]                \n",
            "                                                                 reshape_188[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "model_112 (Functional)          (None, 500, 300)     301         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_17 (Conv1D)              (None, 500, 64)      57664       model_112[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling1D) (None, 250, 64)      0           conv1d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_18 (LSTM)                  (None, 250, 64)      33024       max_pooling1d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_103 (Dense)               (None, 250, 1)       65          lstm_18[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 250)          0           dense_103[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 250)          0           flatten_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_9 (RepeatVector)  (None, 64, 250)      0           activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "permute_47 (Permute)            (None, 250, 64)      0           repeat_vector_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "multiply_28 (Multiply)          (None, 250, 64)      0           lstm_18[0][0]                    \n",
            "                                                                 permute_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_28 (Lambda)              (None, 64)           0           multiply_28[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_104 (Dense)               (None, 5)            325         lambda_28[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 21,563,579\n",
            "Trainable params: 362,279\n",
            "Non-trainable params: 21,201,300\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "21/21 [==============================] - 48s 2s/step - loss: 1.1733 - accuracy: 0.5600 - val_loss: 0.5060 - val_accuracy: 0.9128\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.3454 - accuracy: 0.9060 - val_loss: 0.2515 - val_accuracy: 0.9128\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.1801 - accuracy: 0.9441 - val_loss: 0.2728 - val_accuracy: 0.9195\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.1628 - accuracy: 0.9471 - val_loss: 0.1186 - val_accuracy: 0.9732\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.1173 - accuracy: 0.9627 - val_loss: 0.1529 - val_accuracy: 0.9597\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.0869 - accuracy: 0.9739 - val_loss: 0.1366 - val_accuracy: 0.9597\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.0706 - accuracy: 0.9784 - val_loss: 0.1277 - val_accuracy: 0.9664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Od1F57ZKZw",
        "outputId": "fe633621-9bb6-48f5-ca33-a3c5add8c891"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(\"TEST SET\",f1_score(df_test['class'],np.argmax(model3.predict(X_test), axis=-1),average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST SET 0.9619047619047619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOB6-bg8w5SK",
        "outputId": "6634f181-2278-4131-be18-31fd72151fbf"
      },
      "source": [
        "\n",
        "\n",
        "n=3\n",
        "embLayer = ProjEmbLayer([w2v_embedding,gv_embedding, ft_embedding], str_len)\n",
        "dme = myDynamicMetaEmbedding(str_len)\n",
        "x = dme(embLayer.output)\n",
        "\n",
        "x = Conv1D(64, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling1D()(x)\n",
        "\n",
        "\n",
        "print(x.shape)\n",
        "x = LSTM(64)(x)\n",
        "print(x.shape)\n",
        "\n",
        "out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "model4 = Model(embLayer.input, out)\n",
        "model4.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model4.summary()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model4.fit(X_train, df_train['class'], batch_size=64, epochs=100, verbose=1, validation_split=0.1,callbacks=[callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out (None, 500, 300)\n",
            "(None, 250, 64)\n",
            "(None, 64)\n",
            "Model: \"model_119\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_96 (InputLayer)           [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_57 (Embedding)        (None, 500, 300)     7067100     input_96[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_58 (Embedding)        (None, 500, 300)     7067100     input_96[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_59 (Embedding)        (None, 500, 300)     7067100     input_96[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_190 (Reshape)           (None, 500, 300, 1)  0           embedding_57[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_193 (Reshape)           (None, 500, 300, 1)  0           embedding_58[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_196 (Reshape)           (None, 500, 300, 1)  0           embedding_59[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_191 (Reshape)           (None, 500, 300)     0           reshape_190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_194 (Reshape)           (None, 500, 300)     0           reshape_193[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_197 (Reshape)           (None, 500, 300)     0           reshape_196[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "model_114 (Functional)          (None, 500, 300)     90300       reshape_191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "model_115 (Functional)          (None, 500, 300)     90300       reshape_194[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "model_116 (Functional)          (None, 500, 300)     90300       reshape_197[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_192 (Reshape)           (None, 500, 300, 1)  0           model_114[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_195 (Reshape)           (None, 500, 300, 1)  0           model_115[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_198 (Reshape)           (None, 500, 300, 1)  0           model_116[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 500, 300, 3)  0           reshape_192[0][0]                \n",
            "                                                                 reshape_195[0][0]                \n",
            "                                                                 reshape_198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "model_118 (Functional)          (None, 500, 300)     301         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_18 (Conv1D)              (None, 500, 64)      57664       model_118[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_18 (MaxPooling1D) (None, 250, 64)      0           conv1d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_19 (LSTM)                  (None, 64)           33024       max_pooling1d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_109 (Dense)               (None, 5)            325         lstm_19[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 21,563,514\n",
            "Trainable params: 362,214\n",
            "Non-trainable params: 21,201,300\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "21/21 [==============================] - 47s 2s/step - loss: 1.2313 - accuracy: 0.5265 - val_loss: 0.7823 - val_accuracy: 0.7718\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.5510 - accuracy: 0.8195 - val_loss: 0.4606 - val_accuracy: 0.8725\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.3255 - accuracy: 0.9038 - val_loss: 0.3885 - val_accuracy: 0.8859\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.2630 - accuracy: 0.9210 - val_loss: 0.3804 - val_accuracy: 0.8792\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.1613 - accuracy: 0.9508 - val_loss: 0.1794 - val_accuracy: 0.9396\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.2052 - accuracy: 0.9389 - val_loss: 0.4156 - val_accuracy: 0.8725\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.1891 - accuracy: 0.9403 - val_loss: 0.2576 - val_accuracy: 0.8993\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 44s 2s/step - loss: 0.0973 - accuracy: 0.9724 - val_loss: 0.1840 - val_accuracy: 0.9463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE6AP_ZdcK1T",
        "outputId": "044bba0f-bb30-4672-85ec-f0ba4e3b5f99"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(\"TEST SET\",f1_score(df_test['class'],np.argmax(model4.predict(X_test), axis=-1),average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST SET 0.9564625850340136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cunSInzBuwrM"
      },
      "source": [
        "n=1\n",
        "embLayer = EmbLayer([w2v_embedding], str_len)\n",
        "x = Reshape((str_len,es))(embLayer.output)\n",
        "print(x.shape)\n",
        "x = LSTM(128, dropout=0.2,return_sequences=True)(x)\n",
        "x = LSTM(32)(x)\n",
        "out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "w2v_model = Model(embLayer.input, out)\n",
        "w2v_model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "w2v_model.summary()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "histor = w2v_model.fit(X_train, df_train['class'], batch_size=64, epochs=10, verbose=1, validation_split=0.1,callbacks=[callback])\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'validation'], loc='upper left')\n",
        "# plt.show()\n",
        "\n",
        "print(\"TEST SET\",w2v_model.evaluate(X_test, df_test['class']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWRrx1w6uzXh"
      },
      "source": [
        "n=1\n",
        "embLayer = EmbLayer([gv_embedding], str_len)\n",
        "x = Reshape((str_len,es))(embLayer.output)\n",
        "print(x.shape)\n",
        "x = LSTM(128, dropout=0.2,return_sequences=True)(x)\n",
        "x = LSTM(32)(x)\n",
        "out = Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "gv_model = Model(embLayer.input, out)\n",
        "gv_model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "gv_model.summary()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = gv_model.fit(X_train, df_train['class'], batch_size=64, epochs=10, verbose=1, validation_split=0.1,callbacks=[callback])\n",
        "\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'validation'], loc='upper left')\n",
        "# plt.show()\n",
        "\n",
        "print(\"TEST SET\",gv_model.evaluate(X_test, df_test['class']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "zvUmdSlbu18j",
        "outputId": "33fc48a5-ad6f-46fc-9eef-a9fda0c313ec"
      },
      "source": [
        "n=3\n",
        "embLayer = ProjEmbLayer([w2v_embedding,gv_embedding, ft_embedding], str_len)\n",
        "dme = myDynamicMetaEmbedding(str_len)\n",
        "x = dme(embLayer.output)\n",
        "\n",
        "x = Conv1D(64, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling1D()(x)\n",
        "\n",
        "# x = LSTM(64)(x)\n",
        "# out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "print(x.shape)\n",
        "x = LSTM(64,return_sequences=True)(x)\n",
        "print(x.shape)\n",
        "attention = Dense(1, activation=\"tanh\")(x)\n",
        "print(attention.shape)\n",
        "attention = Flatten()(attention)\n",
        "print(attention.shape)\n",
        "attention = Activation(\"softmax\")(attention)\n",
        "print(attention.shape)\n",
        "# attention = RepeatVector(64 )(attention)\n",
        "# print(attention.shape)\n",
        "attention = Permute([2,1])(attention)\n",
        "print(attention.shape)\n",
        "x = Multiply()([x, attention])\n",
        "print(x.shape)\n",
        "x = Lambda(lambda xin: K.sum(xin, axis=-2),\n",
        "                            output_shape=(64,))(x)\n",
        "\n",
        "\n",
        "print(x.shape)\n",
        "out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "model3 = Model(embLayer.input, out)\n",
        "model3.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model3.summary()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model3.fit(X_train, df_train['class'], batch_size=64, epochs=10, verbose=1, validation_split=0.1,callbacks=[callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out (None, 500, 300)\n",
            "(None, 250, 64)\n",
            "(None, 250, 64)\n",
            "(None, 250, 1)\n",
            "(None, 250)\n",
            "(None, 250)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-151b937e8157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# attention = RepeatVector(64 )(attention)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# print(attention.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2632\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2634\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2635\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    216\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer permute_41 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 250)"
          ]
        }
      ]
    }
  ]
}